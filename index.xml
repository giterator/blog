<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Pranav Venkatram</title><link>https://giterator.github.io/blog/</link><description>Recent content on Pranav Venkatram</description><generator>Hugo -- 0.153.5</generator><language>en-us</language><lastBuildDate>Thu, 01 Jan 2026 09:17:17 -0600</lastBuildDate><atom:link href="https://giterator.github.io/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>Designing a Performant CUDA GEMM Kernel from First Principles</title><link>https://giterator.github.io/blog/posts/gemm/</link><pubDate>Thu, 01 Jan 2026 09:17:17 -0600</pubDate><guid>https://giterator.github.io/blog/posts/gemm/</guid><description>&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In this post, I explore how to implement a performant CUDA GEMM kernel from scratch for NVIDIA GPUs. The goal is to design an efficient kernel grounded in hardware features and first principles, such that its performance characteristics are explainable and achieves performance close to cuBLAS. I examine how the problem naturally decomposes into each level of hardware abstraction (SM, warp, thread) and how to maximize performance at each level through effective use of the memory hierarchy. We start at the lowest level of abstraction (thread) and work our way up to the highest level (SM).&lt;/p&gt;</description></item></channel></rss>